import os
from yaml import dump, load
from genson import SchemaBuilder
from gen3_etl.utils.ioutils import reader
from gen3_etl.utils.defaults import camel_case

def generate_schema(items):
    """Creates json schema based on items."""
    builder = SchemaBuilder()
    builder.add_schema({"type": "object", "properties": {}})
    for item in items:
        builder.add_object(item)
    return builder.to_schema()


def sample(item_paths, limit=100):
    """Reads limit number of records from each file in paths."""
    for path in item_paths:
        i = 0
        for line in reader(path):
            if i < limit:
                yield line
                i = i + 1
            else:
                break

def to_schema(item_paths):
    """Samples path and deduces schema."""
    return generate_schema(sample(item_paths))


def template(type_name):
    """Parses template for type_name."""
    try:
        with open(os.path.join('schemas', '{}.yaml'.format(type_name))) as ins:
            return load(ins)
    except Exception as e:
        with open(os.path.join('schemas', '{}.yaml'.format('default'))) as ins:
            return load(ins)

def generate(item_paths, type_name=None, output_dir=None, schema_path=None, callback=None, links=[]):
    """
    Create schema files.
    Defaults for [type_name,schema_path,output_dir] derived from item_paths.
    Supply your pre_processor to modify schema.
    Returns schema path.
    """
    # default type name to basename of first file
    if not type_name:
        for item_path in item_paths:
            type_name = os.path.basename(item_path).split('.')[0]
            break
    # default output_dir to dirname of first file
    if not output_dir:
        for item_path in item_paths:
            output_dir = os.path.dirname(item_path)
            break
    # default schema_path to output_dir + type_name
    if not schema_path:
        schema_path = os.path.join(output_dir, '{}.yaml'.format(type_name))

    schema = template(type_name)
    imported_properties = to_schema(item_paths)['properties']
    # default to string ['null', 'string'] if only null or string defined
    for k in imported_properties:
        p = imported_properties[k]
        if p.get('type') == 'null':
            p['type'] = ['null', 'string']
        if p.get('type') == 'string':
            p['type'] = ['null', 'string']
        if p.get('type') == 'integer':
            p['type'] = ['null', 'integer']

    schema['properties'].update(imported_properties)

    schema['title'] = camel_case(type_name)
    schema['description'] = 'autogenerated definitions for {}'.format(schema['title'])
    schema['id'] = type_name
    schema['links'] = links

    if callback:
        schema = callback(schema)

    # cross check
    rp = set(schema['required'])
    sp = set(schema['systemProperties'])
    p = set(schema['properties'].keys())
    assert sp.issubset(p), 'schema has system property(s) not found in properties {}'.format(sp - p)
    assert rp.issubset(p), 'schema has required property(s) not found in properties {}'.format(rp - p)


    # for k in schema['properties']:
    #     p = schema['properties'][k]
    #     if '$ref' in p:
    #         continue
    #     assert "'''null'''" not in p['type'],  '{} contains {}'.format(k, "'''null'''")
    #     print(k, p['type'])


    with open(schema_path, 'wt') as ins:
        ins.write(dump(schema, default_flow_style=False))
    return schema_path
